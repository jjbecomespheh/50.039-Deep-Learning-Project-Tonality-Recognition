{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le1FlL_rLUqm",
        "outputId": "4179ad05-cfc3-44c4-b092-39bbcce6eb53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into '50.039-Deep-Learning-Project-Tonality-Recognition'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 25 (delta 6), reused 20 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (25/25), done.\n",
            "/content/50.039-Deep-Learning-Project-Tonality-Recognition\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jjbecomespheh/50.039-Deep-Learning-Project-Tonality-Recognition.git\n",
        "%cd \"50.039-Deep-Learning-Project-Tonality-Recognition\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cG6lAUKQLcxR"
      },
      "outputs": [],
      "source": [
        "!mkdir data\n",
        "%cd data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB8av1yVQiJW",
        "outputId": "f28c2f13-a1de-46e4-f7b6-bf6a745acd63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "archive.zip  waveglow_0\n"
          ]
        }
      ],
      "source": [
        "!ls ../../drive/MyDrive/Waveglow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtfHaBPBLw_A"
      },
      "outputs": [],
      "source": [
        "!unzip ../../drive/MyDrive/Waveglow/archive.zip -d ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JufQxlnoNOqT"
      },
      "outputs": [],
      "source": [
        "!rm -r \"tess toronto emotional speech set data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnKBCHEqRMuH",
        "outputId": "92be52de-7bec-471d-868d-1d853b2cb712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/50.039-Deep-Learning-Project-Tonality-Recognition/train\n"
          ]
        }
      ],
      "source": [
        "%cd ../train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg25VQl_RZDA",
        "outputId": "e2a405c0-c1ac-42ed-8584-b05fdc738979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 2800/2800 [05:45<00:00,  8.10it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "Classes are  {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'ps': 5, 'sad': 6}\n",
            "lstm_model:  LSTM(\n",
            "  (lstm): LSTM(40, 100, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  (layer): Linear(in_features=200, out_features=7, bias=True)\n",
            ")\n",
            "Training started...\n",
            "TRAIN | Epoch: 1/20 | Loss: 0.87 | Accuracy: 0.68\n",
            "TRAIN | Epoch: 2/20 | Loss: 0.57 | Accuracy: 0.80\n",
            "TRAIN | Epoch: 3/20 | Loss: 0.53 | Accuracy: 0.82\n",
            "TRAIN | Epoch: 4/20 | Loss: 0.26 | Accuracy: 0.91\n",
            "TRAIN | Epoch: 5/20 | Loss: 0.25 | Accuracy: 0.92\n",
            "TRAIN | Epoch: 6/20 | Loss: 0.23 | Accuracy: 0.93\n",
            "TRAIN | Epoch: 7/20 | Loss: 0.26 | Accuracy: 0.91\n",
            "TRAIN | Epoch: 8/20 | Loss: 0.28 | Accuracy: 0.91\n",
            "TRAIN | Epoch: 9/20 | Loss: 0.22 | Accuracy: 0.93\n",
            "TRAIN | Epoch: 10/20 | Loss: 0.19 | Accuracy: 0.94\n",
            "TRAIN | Epoch: 11/20 | Loss: 0.25 | Accuracy: 0.92\n",
            "TRAIN | Epoch: 12/20 | Loss: 0.24 | Accuracy: 0.92\n",
            "TRAIN | Epoch: 13/20 | Loss: 0.27 | Accuracy: 0.91\n",
            "TRAIN | Epoch: 14/20 | Loss: 0.25 | Accuracy: 0.92\n",
            "TRAIN | Epoch: 15/20 | Loss: 0.20 | Accuracy: 0.94\n",
            "TRAIN | Epoch: 16/20 | Loss: 0.19 | Accuracy: 0.94\n",
            "TRAIN | Epoch: 17/20 | Loss: 0.17 | Accuracy: 0.94\n",
            "TRAIN | Epoch: 18/20 | Loss: 0.19 | Accuracy: 0.94\n",
            "TRAIN | Epoch: 19/20 | Loss: 0.25 | Accuracy: 0.91\n",
            "TRAIN | Epoch: 20/20 | Loss: 0.39 | Accuracy: 0.87\n",
            "Testing Started...\n",
            "TEST | Average Accuracy per 28 Loaders: 0.86429\n"
          ]
        }
      ],
      "source": [
        "!python LSTMTrain.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "V4c6t4a4RiRO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "LSTMTrain",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
